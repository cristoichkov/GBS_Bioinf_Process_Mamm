n.colmeans(state.x77, 2.5)
n.colmeans = function(df, n){
aggregate(x = df,
by = list(gl(ceiling(nrow(df)/n), n)[1:nrow(df)]),
FUN = mean)
}
n.colmeans(state.x77, 2.5)
n.colmeans(state.x77, 10)
n.colmeans = function(df, n =10){
aggregate(x = df,
by = list(gl(ceiling(nrow(df)/n), n)[1:nrow(df)]),
FUN = mean)
}
n.colmeans(state.x77)
n.colmeans = function(df, n){
aggregate(x = df,
by = list(gl(ceiling(nrow(df)/n), n)[1:nrow(df)]),
FUN = mean)
}
n.colmeans(state.x77)
n.colmeans(state.x77, 10)
n.colmeans(state.x77, 5)
n.colmeans(state.x77, 3)
n.colmeans(state.x77, 2.5)
library(ggtree)
library(Biostrings)
library(ggplot2)
library(seqinr)
library(tidyverse)
library(phangorn)
set.seed(2015-12-21)
tree <- rtree(30)
p <- ggtree(tree) + xlim(NA, 6)
p + geom_cladelabel(node=45, label="test label") +
geom_cladelabel(node=34, label="another clade")
ggtree(tree, lwd = 2, color = "darkgreen", alpha = 0.8, right = TRUE) +
geom_tiplab(size = 7, angle = 90, offset = 0.05) +
geom_point(aes(shape = isTip, color = isTip), size = 5, alpha = 0.6)
seqs6 = simSeq(tree, l = 60, type = "DNA", bf = c(1, 1, 3, 3)/8, rate = 0.1)
seqs6
class(seqs6)
seqs6
mat6df = data.frame(as.character(seqs6))
View(mat6df)
gheatmap(p, mat6df[, 1:60], offset = 0.01, colnames = FALSE)
setwd("/media/cristoichkov/Stoich/Doctorado/Fotos/Espinas/bin")
vec <- c(2, 3, 6, 2, 7)
class(vec)
typeof(vec)
vec_char <- c("blanco", "rojo", "azul", "rojo")
typeof(vec_char)
class(vec_char)
vec <- (1, 4, "blanco", "azul")
length(vec_char)
x <- c(1, 5.4, TRUE, "hello")
vec <- (1, 4, "blanco", "azul")length(vec_char)
vec <- (1, 4, "blanco", "azul")
vec <- c(1, 4, "blanco", "azul")
class(vec)
1:7
x <- 1:7
x <- 1:7; x
x <- 1:7
y <- 2:-2
seq(1, 3, by=0.2)
seq(1, 5, length.out=4)
seq(1, 5, length.out=4)
5/4
1 + 1.333333
1 + 1.333333 +1.3333
1 + 1.333333 +1.3333 + 1.3333
vec_num <- c(2, 3, 6, 2, 7, 10, 23)
vec_num[3]
vec_num[-6]
vec_num[vec_num < 7]
vec_num[vec_num <= 7]
x <- c(2, 3, 5, 4, 3)
x*5
x+5
y <- c(5, 4, 8, 7, 10)
x + y
y <- c(5, 4, 8, 7, 10, 6)
x + y
y + x
x <- c(1, 5)
x+5
y <- c(5, 2, 4, 5, 4, 2, 4, 5)
x + y
fruits <- c("Apple", "oranges", "banana")
vegetables <- c("cabbage", "spinach", "tomatoes")
all_basket_items <- c(fruits, vegetables)
all_basket_items
525/3
175*3
head(iris)
?head
head(iris, 10)
head(iris, -10)
tail(iris)
str(iris)
summary(iris)
colnames(iris)
length(iris)
nrow(iris)
iris[1:50]
iris[1:50,]
iris <- iris
iris
ncol(iris)
iris$Species == "setosa"
iris[iris$Species == "setosa", ]
summary(iris)
ls
ls()
iris[["Species"]]
iris["Species"]
iris[1:5,"Species"]
iris[1:50, "Species"]
iris[1:50, 2]
mean(iris[1:50, 2])
iris[[4]]
iris[[5]]
iris[5]
apply(iris, 1, FUN = sum)
apply(iris, MARGIN = 1, FUN = sum)
apply(iris[,1], MARGIN = 1, FUN = sum)
apply(iris[,1:4], MARGIN = 1, FUN = sum)
apply(iris[,1], MARGIN = 2, FUN = sum)
head(iris)
5.1     +    3.5     +     1.4    +     0.2
apply(iris[,1:4], MARGIN = 2, FUN = sum)
apply(iris[,1:4], MARGIN = 2, FUN = mean)
iris
quantile(iris$Sepal.Length)
boxplot(iris$Species, iris$Sepal.Length)
boxplot(, iris$Sepal.Length)
boxplot(iris$Sepal.Length)
boxplot(, iris$Sepal.Length)
boxplot(, iris$Sepal.Length)
boxplot(iris$Sepal.Length)
iris$size <- ifelse(iris$Sepal.Length < 5.1, "one",
ifelse((iris$Sepal.Length>=5.1) & (iris$Sepal.Length < 5.8), "two",
ifelse((iris$Sepal.Length >=5.8) & (iris$Sepal.Length < 6.4), "tree", "four")))
View(iris)
iris$size
setwd("/media/cristoichkov/Stoich/ipyrad/out/brenda/no_genome_mis_dat_outfiles")
part_find <- read.csv("length_locus.csv")
part_find
1:length(part_find)
1:nrow(part_find)
head(part_find)
part_find[1+1,3]
part_find[1+1,1]
vec_pf <- vector(paste0(part_find[1,1], "=", 1, "-", part_find[1,3]))
part_find[1,1], "=", 1, "-", part_find[1,3])
paste0(part_find[1,1], "=", 1, "-", part_find[1,3])
vec_pf <- vector(paste0(part_find[1,1], "=", 1, "-", part_find[1,3], ";"))
paste0(part_find[1,1], "=", 1, "-", part_find[1,3], ";")
one <- paste0(part_find[1,1], "=", 1, "-", part_find[1,3], ";")
vec_pf <- vector(one)
vec_pf <- as.vector(one)
vec_pf
head(part_find)
for (i in 1:nrow(part_find)){
pf1 <- part_find[i, 3]
pf2 <- part_find[i+1,3]
name <- part_find[i+1,1]
two <- paste0(part_find[i+1,1], "=", part_find[i,3]+1, "-", part_find[1+1,3], ";")
vec_pf <- c(vec_pf, two)
}
vec_pf
part_find <- read.csv("length_locus.csv")
one <- paste0(part_find[1,1], "=", 1, "-", part_find[1,3], ";")
vec_pf <- as.vector(one)
for (i in 1:nrow(part_find)){
pf1 <- part_find[i, 3]
pf2 <- part_find[i+1,3]
name <- part_find[i+1,1]
two <- paste0(part_find[i+1,1], "=", part_find[i,3]+1, "-", part_find[i+1,3], ";")
vec_pf <- c(vec_pf, two)
}
vec_pf
View(part_find)
part_find <- read.csv("length_locus.csv")
one <- paste0(part_find[1,1], "=", 1, "-", part_find[1,3], ";")
vec_pf <- as.vector(one)
for (i in 1:nrow(part_find)){
if (i == 497){
pf1 <- part_find[i, 3]
pf2 <- part_find[i+1,3]
name <- part_find[i+1,1]
two <- paste0(part_find[i+1,1], "=", part_find[i,3]+1, "-", part_find[i+1,3], ";")
vec_pf <- c(vec_pf, two)
break
}
}
part_find <- read.csv("length_locus.csv")
one <- paste0(part_find[1,1], "=", 1, "-", part_find[1,3], ";")
vec_pf <- as.vector(one)
for (i in 1:nrow(part_find)){
pf1 <- part_find[i, 3]
pf2 <- part_find[i+1,3]
name <- part_find[i+1,1]
two <- paste0(part_find[i+1,1], "=", part_find[i,3]+1, "-", part_find[i+1,3], ";")
vec_pf <- c(vec_pf, two)
}
vec_pf
i
vec_pf <- vec_pf[1:i]
vec_pf <- as.data.frame(vec_pf)
View(vec_pf)
write.table(vec_pf, file = "partitio_finder.txt")
str(vec_pf)
write.table(vec_pf, file = "partitio_finder.txt", col.names=FALSE)
write.table(vec_pf, file = "partitio_finder.txt", col.names=FALSE, row.names=FALSE))
write.table(vec_pf, file = "partitio_finder.txt", col.names=FALSE, row.names=FALSE)
write.table(vec_pf, file = "partitio_finder.txt", col.names=FALSE, row.names=FALSE, quotes=FALSE)
write.table(vec_pf, file = "partitio_finder.txt", col.names=FALSE, row.names=FALSE, quote = FALSE)
setwd("~/Repos/GBS_Bioinf_Process_Mamm/bin")
## Defines the name of the function, which accepts as parameters:
## file = "../file.loci", n_sambles = # samples
ipyrad_loci_to_fasta <- function(file, n_samples){
ipyrad_Loci <- readLines(file) ## Returns a list containing the lines in "file"
breakLines <- grep("//", ipyrad_Loci, fixed = TRUE) ## create a vector with the # of the rows that contain "//"
firstLocusLines <- c(1, (breakLines[1:(length(breakLines)-1)] + 1)) ## create a vector with the start of sequences of each locus
## loop to extract each locus and create a dataframe for each one
for (k in 1:length(breakLines)){ ## list the length of breakLines vector
loc <- ipyrad_Loci[firstLocusLines[k]:(breakLines[k]-1)]  ## generate a range that is the number of row for each locus
loc_split <- strsplit(loc, "\\s+") ## separate each locus and put it in a list
seq_loc <- data.frame() ## empty dataframe
## loop to extract all the sequences per locus and create a dataframe for each one
for (i in 1:length(loc_split)){ ## list the length of loc_split list
name <- data.frame(loc_split[[i]][1]) ## extract the name for each locus
seq <- data.frame(loc_split[[i]][2]) ## extract the sequence for each sample per locus
df_nam_seq <- cbind(name, seq) ## combine the sample id and its sequence per locus
colnames(df_nam_seq) <- c("Id", paste0("locus_", k)) ## Change the column names
seq_loc <- rbind(seq_loc, df_nam_seq) ## combine the sequences of all samples per locus
}
assign(paste0("locus_", k), seq_loc) ## create a dataframe for each locus
}
lst <- mget(paste0("locus_", 1:length(breakLines))) ## create a list of all locus dataframes
locus_lenght <- data.frame() ## empty dataframe
## loop to create a dataframe with the length of each locus
for (n in 1:length(lst)){
loc_names <- data.frame(paste0("locus_", n)) ## id of each locus
seq_lenght <- data.frame(nchar(as.vector(lst[[n]][2,2]))) ## length of each locus
df_length <- cbind(loc_names, seq_lenght) ## combine the locus id and its length
colnames(df_length) <- c("Locus", "Lenght") ## Change the column names
locus_lenght <- rbind(locus_lenght, df_length) ## combine the lenght of all locus
}
suppressWarnings(locus_df_all <- reduce(lst, full_join, by = "Id")) ## combine all locus by Id in only one dataframe
locus_df_all <- locus_df_all %>% slice(1:n_samples) ## select only the number of samples
## loop to replace <NA> values to "-" character
for (g in 1:nrow(locus_df_all)){
locus_df_all[,f] <- fct_explicit_na(locus_df_all[,f], na_level =  strrep("-", locus_lenght[f-1,2]))
}
pre_fast <- locus_df_all %>% unite("loci", matches("^locus"), sep = "") ## unite all locus y one locus
dataframe2fas(pre_fast, file = "locus_fasta.fas") ## convert the dataframe to fasta file
locus_lenght$cumsum <- cumsum(locus_lenght$Lenght) ## convert the dataframe to fasta file
write.csv(locus_lenght, file = "length_locus.csv", row.names = FALSE) ## save the length dataframe in .csv file
one <- paste0(locus_lenght[1,1], "=", 1, "-", locus_lenght[1,3], ";")
vec_pf <- as.vector(one)
for (p in 1:nrow(locus_lenght)){
pf1 <- locus_lenght[p, 3]
pf2 <- locus_lenght[p+1,3]
name <- locus_lenght[p+1,1]
two <- paste0(locus_lenght[p+1,1], "=", locus_lenght[p,3]+1, "-", locus_lenght[p+1,3], ";")
vec_pf <- c(vec_pf, two)
}
vec_pf <- vec_pf[1:p]
vec_pf <- as.data.frame(vec_pf)
str(vec_pf)
write.table(vec_pf, file = "partitio_finder.txt", col.names=FALSE, row.names=FALSE, quote = FALSE)
}
setwd("/media/cristoichkov/Stoich/ipyrad/out/brenda/no_genome_mis_dat_outfiles")
ipyrad_loci_to_fasta("no_genome_mis_dat.loci")
install.packages("tidyverse")
install.packages("seqRFLP")
ipyrad_loci_to_fasta("no_genome_mis_dat.loci")
## Defines the name of the function, which accepts as parameters:
## file = "../file.loci", n_sambles = # samples
ipyrad_loci_to_fasta <- function(file, n_samples){
ipyrad_Loci <- readLines(file) ## Returns a list containing the lines in "file"
breakLines <- grep("//", ipyrad_Loci, fixed = TRUE) ## create a vector with the # of the rows that contain "//"
firstLocusLines <- c(1, (breakLines[1:(length(breakLines)-1)] + 1)) ## create a vector with the start of sequences of each locus
## loop to extract each locus and create a dataframe for each one
for (k in 1:length(breakLines)){ ## list the length of breakLines vector
loc <- ipyrad_Loci[firstLocusLines[k]:(breakLines[k]-1)]  ## generate a range that is the number of row for each locus
loc_split <- strsplit(loc, "\\s+") ## separate each locus and put it in a list
seq_loc <- data.frame() ## empty dataframe
## loop to extract all the sequences per locus and create a dataframe for each one
for (i in 1:length(loc_split)){ ## list the length of loc_split list
name <- data.frame(loc_split[[i]][1]) ## extract the name for each locus
seq <- data.frame(loc_split[[i]][2]) ## extract the sequence for each sample per locus
df_nam_seq <- cbind(name, seq) ## combine the sample id and its sequence per locus
colnames(df_nam_seq) <- c("Id", paste0("locus_", k)) ## Change the column names
seq_loc <- rbind(seq_loc, df_nam_seq) ## combine the sequences of all samples per locus
}
assign(paste0("locus_", k), seq_loc) ## create a dataframe for each locus
}
lst <- mget(paste0("locus_", 1:length(breakLines))) ## create a list of all locus dataframes
locus_lenght <- data.frame() ## empty dataframe
## loop to create a dataframe with the length of each locus
for (n in 1:length(lst)){
loc_names <- data.frame(paste0("locus_", n)) ## id of each locus
seq_lenght <- data.frame(nchar(as.vector(lst[[n]][2,2]))) ## length of each locus
df_length <- cbind(loc_names, seq_lenght) ## combine the locus id and its length
colnames(df_length) <- c("Locus", "Lenght") ## Change the column names
locus_lenght <- rbind(locus_lenght, df_length) ## combine the lenght of all locus
}
suppressWarnings(locus_df_all <- purrr::reduce(lst, full_join, by = "Id")) ## combine all locus by Id in only one dataframe
locus_df_all <- locus_df_all %>% slice(1:n_samples) ## select only the number of samples
## loop to replace <NA> values to "-" character
for (g in 1:nrow(locus_df_all)){
locus_df_all[,f] <- fct_explicit_na(locus_df_all[,f], na_level =  strrep("-", locus_lenght[f-1,2]))
}
pre_fast <- locus_df_all %>% unite("loci", matches("^locus"), sep = "") ## unite all locus y one locus
dataframe2fas(pre_fast, file = "locus_fasta.fas") ## convert the dataframe to fasta file
locus_lenght$cumsum <- cumsum(locus_lenght$Lenght) ## convert the dataframe to fasta file
write.csv(locus_lenght, file = "length_locus.csv", row.names = FALSE) ## save the length dataframe in .csv file
one <- paste0(locus_lenght[1,1], "=", 1, "-", locus_lenght[1,3], ";")
vec_pf <- as.vector(one)
for (p in 1:nrow(locus_lenght)){
pf1 <- locus_lenght[p, 3]
pf2 <- locus_lenght[p+1,3]
name <- locus_lenght[p+1,1]
two <- paste0(locus_lenght[p+1,1], "=", locus_lenght[p,3]+1, "-", locus_lenght[p+1,3], ";")
vec_pf <- c(vec_pf, two)
}
vec_pf <- vec_pf[1:p]
vec_pf <- as.data.frame(vec_pf)
str(vec_pf)
write.table(vec_pf, file = "partitio_finder.txt", col.names=FALSE, row.names=FALSE, quote = FALSE)
}
ipyrad_loci_to_fasta("no_genome_mis_dat.loci")
library(tidyverse)
library(seqRFLP)
ipyrad_loci_to_fasta("no_genome_mis_dat.loci")
ipyrad_loci_to_fasta("no_genome_mis_dat.loci", 23)
## Defines the name of the function, which accepts as parameters:
## file = "../file.loci", n_sambles = # samples
ipyrad_loci_to_fasta <- function(file, n_samples){
ipyrad_Loci <- readLines(file) ## Returns a list containing the lines in "file"
breakLines <- grep("//", ipyrad_Loci, fixed = TRUE) ## create a vector with the # of the rows that contain "//"
firstLocusLines <- c(1, (breakLines[1:(length(breakLines)-1)] + 1)) ## create a vector with the start of sequences of each locus
## loop to extract each locus and create a dataframe for each one
for (k in 1:length(breakLines)){ ## list the length of breakLines vector
loc <- ipyrad_Loci[firstLocusLines[k]:(breakLines[k]-1)]  ## generate a range that is the number of row for each locus
loc_split <- strsplit(loc, "\\s+") ## separate each locus and put it in a list
seq_loc <- data.frame() ## empty dataframe
## loop to extract all the sequences per locus and create a dataframe for each one
for (i in 1:length(loc_split)){ ## list the length of loc_split list
name <- data.frame(loc_split[[i]][1]) ## extract the name for each locus
seq <- data.frame(loc_split[[i]][2]) ## extract the sequence for each sample per locus
df_nam_seq <- cbind(name, seq) ## combine the sample id and its sequence per locus
colnames(df_nam_seq) <- c("Id", paste0("locus_", k)) ## Change the column names
seq_loc <- rbind(seq_loc, df_nam_seq) ## combine the sequences of all samples per locus
}
assign(paste0("locus_", k), seq_loc) ## create a dataframe for each locus
}
lst <- mget(paste0("locus_", 1:length(breakLines))) ## create a list of all locus dataframes
locus_lenght <- data.frame() ## empty dataframe
## loop to create a dataframe with the length of each locus
for (n in 1:length(lst)){
loc_names <- data.frame(paste0("locus_", n)) ## id of each locus
seq_lenght <- data.frame(nchar(as.vector(lst[[n]][2,2]))) ## length of each locus
df_length <- cbind(loc_names, seq_lenght) ## combine the locus id and its length
colnames(df_length) <- c("Locus", "Lenght") ## Change the column names
locus_lenght <- rbind(locus_lenght, df_length) ## combine the lenght of all locus
}
suppressWarnings(locus_df_all <- reduce(lst, full_join, by = "Id")) ## combine all locus by Id in only one dataframe
locus_df_all <- locus_df_all %>% slice(1:n_samples) ## select only the number of samples
## loop to replace <NA> values to "-" character
for (f in 1:nrow(locus_df_all)){
locus_df_all[,f] <- fct_explicit_na(locus_df_all[,f], na_level =  strrep("-", locus_lenght[f-1,2]))
}
pre_fast <- locus_df_all %>% unite("loci", matches("^locus"), sep = "") ## unite all locus y one locus
dataframe2fas(pre_fast, file = "locus_fasta.fas") ## convert the dataframe to fasta file
locus_lenght$cumsum <- cumsum(locus_lenght$Lenght) ## convert the dataframe to fasta file
write.csv(locus_lenght, file = "length_locus.csv", row.names = FALSE) ## save the length dataframe in .csv file
one <- paste0(locus_lenght[1,1], "=", 1, "-", locus_lenght[1,3], ";")
vec_pf <- as.vector(one)
for (p in 1:nrow(locus_lenght)){
pf1 <- locus_lenght[p, 3]
pf2 <- locus_lenght[p+1,3]
name <- locus_lenght[p+1,1]
two <- paste0(locus_lenght[p+1,1], "=", locus_lenght[p,3]+1, "-", locus_lenght[p+1,3], ";")
vec_pf <- c(vec_pf, two)
}
vec_pf <- vec_pf[1:p]
vec_pf <- as.data.frame(vec_pf)
str(vec_pf)
write.table(vec_pf, file = "partitio_finder.txt", col.names=FALSE, row.names=FALSE, quote = FALSE)
}
ipyrad_loci_to_fasta("no_genome_mis_dat.loci", 23)
## Defines the name of the function, which accepts as parameters:
## file = "../file.loci", n_sambles = # samples
ipyrad_loci_to_fasta <- function(file, n_samples){
ipyrad_Loci <- readLines(file) ## Returns a list containing the lines in "file"
breakLines <- grep("//", ipyrad_Loci, fixed = TRUE) ## create a vector with the # of the rows that contain "//"
firstLocusLines <- c(1, (breakLines[1:(length(breakLines)-1)] + 1)) ## create a vector with the start of sequences of each locus
## loop to extract each locus and create a dataframe for each one
for (k in 1:length(breakLines)){ ## list the length of breakLines vector
loc <- ipyrad_Loci[firstLocusLines[k]:(breakLines[k]-1)]  ## generate a range that is the number of row for each locus
loc_split <- strsplit(loc, "\\s+") ## separate each locus and put it in a list
seq_loc <- data.frame() ## empty dataframe
## loop to extract all the sequences per locus and create a dataframe for each one
for (i in 1:length(loc_split)){ ## list the length of loc_split list
name <- data.frame(loc_split[[i]][1]) ## extract the name for each locus
seq <- data.frame(loc_split[[i]][2]) ## extract the sequence for each sample per locus
df_nam_seq <- cbind(name, seq) ## combine the sample id and its sequence per locus
colnames(df_nam_seq) <- c("Id", paste0("locus_", k)) ## Change the column names
seq_loc <- rbind(seq_loc, df_nam_seq) ## combine the sequences of all samples per locus
}
assign(paste0("locus_", k), seq_loc) ## create a dataframe for each locus
}
lst <- mget(paste0("locus_", 1:length(breakLines))) ## create a list of all locus dataframes
locus_lenght <- data.frame() ## empty dataframe
## loop to create a dataframe with the length of each locus
for (n in 1:length(lst)){
loc_names <- data.frame(paste0("locus_", n)) ## id of each locus
seq_lenght <- data.frame(nchar(as.vector(lst[[n]][2,2]))) ## length of each locus
df_length <- cbind(loc_names, seq_lenght) ## combine the locus id and its length
colnames(df_length) <- c("Locus", "Lenght") ## Change the column names
locus_lenght <- rbind(locus_lenght, df_length) ## combine the lenght of all locus
}
suppressWarnings(locus_df_all <- reduce(lst, full_join, by = "Id")) ## combine all locus by Id in only one dataframe
locus_df_all <- locus_df_all %>% slice(1:n_samples) ## select only the number of samples
## loop to replace <NA> values to "-" character
for (f in 1:nrow(locus_df_all)){
locus_df_all[,f] <- fct_explicit_na(locus_df_all[,f], na_level =  strrep("-", locus_lenght[f-1,2]))
}
pre_fast <- locus_df_all %>% unite("loci", matches("^locus"), sep = "") ## unite all locus y one locus
dataframe2fas(pre_fast, file = "locus_fasta.fas") ## convert the dataframe to fasta file
locus_lenght$cumsum <- cumsum(locus_lenght$Lenght) ## convert the dataframe to fasta file
write.csv(locus_lenght, file = "length_locus.csv", row.names = FALSE) ## save the length dataframe in .csv file
one <- paste0(locus_lenght[1,1], "=", 1, "-", locus_lenght[1,3], ";")
vec_pf <- as.vector(one)
for (p in 1:nrow(locus_lenght)){
pf1 <- locus_lenght[p, 3]
pf2 <- locus_lenght[p+1,3]
name <- locus_lenght[p+1,1]
two <- paste0(locus_lenght[p+1,1], "=", locus_lenght[p,3]+1, "-", locus_lenght[p+1,3], ";")
vec_pf <- c(vec_pf, two)
}
vec_pf <- vec_pf[1:p]
vec_pf <- as.data.frame(vec_pf)
write.table(vec_pf, file = "partitio_finder.txt", col.names=FALSE, row.names=FALSE, quote = FALSE)
}
ipyrad_loci_to_fasta("no_genome_mis_dat.loci", 23)
setwd("~/Repos/GBS_Bioinf_Process_Mamm/bin")
setwd("~/Repos/GBS_Bioinf_Process_Mamm/bin")
## function to extract a list of nodes and its tip labels from a tree
source("extract_nodes_tips.R")
setwd("~/Repos/GBS_Bioinf_Process_Mamm/bin")
## function to extract a list of nodes and its tip labels from a tree
source("extract_nodes_tips.R")
library(ape)
library(treeio)
library(ggtree)
library(ggplot2)
library(dplyr)
library(phylobase)
install.packages("phylobase")
## function to extract a list of nodes and its tip labels from a tree
source("extract_nodes_tips.R")
install.packages("phylotools")
## function to extract a list of nodes and its tip labels from a tree
source("extract_nodes_tips.R")
tree_run1 <- read.raxml("../out/tree_raxml/RAxML_bipartitionsBranchLabels.opt_89_9_40_run1")
ggtree(tree_1) + geom_tiplab() + geom_label2(aes(label = node), size = 3) + geom_rootpoint()
tree_1 <- read.raxml("../out/tree_raxml/RAxML_bipartitionsBranchLabels.opt_89_9_40_run1")
ggtree(tree_1) + geom_tiplab() + geom_label2(aes(label = node), size = 3) + geom_rootpoint()
names <- read.csv("../meta/Mamm_names.csv", header = FALSE, sep = "\t")
tree_run1 <-  rename_taxa(tree_run1, names, V1, V2)
tree_1 <-  rename_taxa(tree_run1, names, V1, V2)
tree_1 <-  rename_taxa(tree_1, names, V1, V2)
ggtree(tree_1) + geom_tiplab() + geom_label2(aes(label = node), size = 3) + geom_rootpoint()
tree_1 <- groupClade(tree_1, .node = c(126, 115, 112, 141, 138, 108, 83, 93, 97))
View(tree_1)
tree_1 <- read.raxml("../out/tree_raxml/RAxML_bipartitionsBranchLabels.opt_89_9_40_run1")
names <- read.csv("../meta/Mamm_names.csv", header = FALSE, sep = "\t")
tree_1 <-  rename_taxa(tree_1, names, V1, V2)
phylo <- groupClade(tree_1, .node = c(126, 115, 112, 141, 138, 108, 83, 93, 97))
tree_1@phylo <- phylo
ggtree(tree_1) + geom_tiplab() + geom_label2(aes(label = bootstrap), size = 3) + geom_rootpoint()
ggtree(tree_1, aes(color=group)) + geom_tiplab() + geom_label2(aes(label = bootstrap), size = 3) + geom_rootpoint()
tree_1 <- read.raxml("../out/tree_raxml/RAxML_bipartitionsBranchLabels.opt_89_9_40_run1")
names <- read.csv("../meta/Mamm_names.csv", header = FALSE, sep = "\t")
tree_1 <-  rename_taxa(tree_1, names, V1, V2)
phylo <- groupClade(tree_1, .node = c(126, 115, 112, 141, 138, 108, 83, 93, 97, 81, 77, 146))
tree_1@phylo <- phylo
ggtree(tree_1, aes(color=group)) + geom_tiplab() + geom_label2(aes(label = bootstrap), size = 3) + geom_rootpoint()
ggtree(tree_1) + geom_tiplab() + geom_label2(aes(label = bootstrap), size = 3) + geom_rootpoint()
tree_2 <- read.raxml("../out/tree_raxml/RAxML_bipartitionsBranchLabels.opt_89_9_40_run1")
names <- read.csv("../meta/Mamm_names.csv", header = FALSE, sep = "\t")
tree_2 <-  rename_taxa(tree_2, names, V1, V2)
ggtree(tree_2) + geom_tiplab() + geom_label2(aes(label = node), size = 3) + geom_rootpoint()
ggtree(tree_2) + geom_tiplab() + geom_label2(aes(label = bootstrap), size = 3) + geom_rootpoint()
phylo <- groupClade(tree_2, .node = c(126, 115, 112, 141, 138, 108, 83, 93, 97, 81, 77, 146))
tree_2@phylo <- phylo
ggtree(tree_2, aes(color=group)) + geom_tiplab() + geom_label2(aes(label = bootstrap), size = 3) + geom_rootpoint()
tree_2 <- read.raxml("../out/tree_raxml/RAxML_bipartitionsBranchLabels.opt_89_9_60_run1")
names <- read.csv("../meta/Mamm_names.csv", header = FALSE, sep = "\t")
tree_2 <-  rename_taxa(tree_2, names, V1, V2)
ggtree(tree_2) + geom_tiplab() + geom_label2(aes(label = bootstrap), size = 3) + geom_rootpoint()
ggtree(tree_2) + geom_tiplab() + geom_label2(aes(label = node), size = 3) + geom_rootpoint()
tree_3 <- read.raxml("../out/tree_raxml/RAxML_bipartitionsBranchLabels.opt_89_9_80_run1")
names <- read.csv("../meta/Mamm_names.csv", header = FALSE, sep = "\t")
tree_3 <-  rename_taxa(tree_3, names, V1, V2)
ggtree(tree_3) + geom_tiplab() + geom_label2(aes(label = node), size = 3) + geom_rootpoint()
ggtree(tree_3) + geom_tiplab() + geom_label2(aes(label = bootstrap), size = 3) + geom_rootpoint()
